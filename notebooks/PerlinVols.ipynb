{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurite_sandbox as nes\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import neurite as ne\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perlin_generation(num_to_gen,\n",
    "                      num_labels_range=[5,20],\n",
    "                      max_blur_std=30,\n",
    "                      shapes_im_max_std_range=[0.5, 5],\n",
    "                      shapes_warp_max_std_range=[4.0, 15.0],\n",
    "                      std_min_range=[0.01, 0.1],\n",
    "                      std_max_range=[0.2, 1],\n",
    "                      lab_int_interimage_std_range=[0.01, 0.1],\n",
    "                      warp_std_range=[1, 10],\n",
    "                      bias_res_range=[32, 50],\n",
    "                      bias_std_range=[0.1, 1.0],\n",
    "                      blur_std_range=[0.5, 5],\n",
    "                      visualize=False,\n",
    "                      min_label=2000,\n",
    "                      ):\n",
    "\n",
    "    # Gen parameters\n",
    "    num_labels = np.random.randint(low=num_labels_range[0], high=num_labels_range[1])\n",
    "    shapes_im_max_std = np.random.uniform(shapes_im_max_std_range[0], shapes_im_max_std_range[1])\n",
    "    shapes_warp_max_std = np.random.uniform(shapes_warp_max_std_range[0], shapes_warp_max_std_range[1])\n",
    "    std_min = np.random.uniform(std_min_range[0], std_min_range[1])\n",
    "    std_max = np.random.uniform(std_max_range[0], std_max_range[1])\n",
    "    lab_int_interimage_std = np.random.uniform(lab_int_interimage_std_range[0], lab_int_interimage_std_range[1])\n",
    "    warp_std = np.random.uniform(warp_std_range[0], warp_std_range[1])\n",
    "    bias_res = np.random.uniform(bias_res_range[0], bias_res_range[1])\n",
    "    bias_std = np.random.uniform(bias_std_range[0], bias_std_range[1])\n",
    "    blur_std = np.random.uniform(blur_std_range[0], blur_std_range[1])\n",
    "    \n",
    "    # Gen tasks\n",
    "    images, label_maps, lab = nes.tf.utils.synth.perlin_nshot_task(in_shape=(256,256),\n",
    "                                                                  num_gen=num_to_gen,\n",
    "                                                                  num_label=num_labels,\n",
    "                                                                  shapes_im_scales=(32, 64, 128),\n",
    "                                                                  shapes_warp_scales=(16, 32, 64, 128),\n",
    "                                                                  shapes_im_max_std=shapes_im_max_std,\n",
    "                                                                  shapes_warp_max_std=shapes_warp_max_std,\n",
    "                                                                  min_int=0,\n",
    "                                                                  max_int=1,\n",
    "                                                                  std_min=std_min,\n",
    "                                                                  std_max=std_max,\n",
    "                                                                  lab_int_interimage_std=lab_int_interimage_std,\n",
    "                                                                  warp_std=warp_std,\n",
    "                                                                  warp_res=(8, 16, 32, 64),\n",
    "                                                                  bias_res=bias_res,\n",
    "                                                                  bias_std=bias_std,\n",
    "                                                                  blur_std=blur_std)\n",
    "    \n",
    "    \n",
    "    flattened_labels = [np.argmax(f, -1) for f in label_maps]\n",
    "    all_labels = np.unique(lab).tolist()\n",
    "\n",
    "    min_pixels = min_label\n",
    "    background_labels = []\n",
    "    for lab in all_labels:\n",
    "        for lm in label_maps:\n",
    "            if np.count_nonzero(lm[..., lab]) < min_pixels:\n",
    "                all_labels.remove(lab)\n",
    "                background_labels.append(background_labels)\n",
    "                break\n",
    "\n",
    "    assert len(all_labels) > 0\n",
    "\n",
    "    label_map_big_labels = [f[..., np.array(all_labels)] for f in label_maps]\n",
    "\n",
    "    label_map_big_labels_wbg = []\n",
    "    foreground_labels = []\n",
    "    background_labels = []\n",
    "    for f in label_map_big_labels:\n",
    "        foreground_label = (np.sum(f, axis=-1))[..., np.newaxis]\n",
    "        background_label = (1-np.sum(f, axis=-1))[..., np.newaxis]\n",
    "        foreground_labels.append(foreground_label)\n",
    "        background_labels.append(background_label)\n",
    "        new_f = np.concatenate([background_label, f], -1)\n",
    "        label_map_big_labels_wbg.append(new_f)\n",
    "    flattened_label_map_big_labels_wbg = [np.argmax(f, -1) for f in label_map_big_labels_wbg]\n",
    "    \n",
    "    if visualize:\n",
    "        ne.plot.slices(images, do_colorbars=True)\n",
    "        ne.plot.slices(flattened_labels, cmaps=['tab20c'], do_colorbars=True)\n",
    "        ne.plot.slices(foreground_labels, do_colorbars=True)\n",
    "        ne.plot.slices(background_labels, do_colorbars=True)\n",
    "        ne.plot.slices(flattened_label_map_big_labels_wbg, cmaps=['tab20c'], do_colorbars=True)\n",
    "    \n",
    "    return images, flattened_label_map_big_labels_wbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2376af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root = \"/home/vib9/src/MegaMedical/megamedical/datasets/Synthetic/original_unzipped\"\n",
    "for task in tqdm_notebook(range(100)):\n",
    "    task_root = os.path.join(root, f\"task_{task}\")\n",
    "    images, label_maps = perlin_generation(num_to_gen=100, visualize=False)\n",
    "    for subj_idx, (image, label_map) in enumerate(zip(images, label_maps)):\n",
    "        img_root = os.path.join(task_root, \"imgs\")\n",
    "        label_root = os.path.join(task_root, \"segs\")\n",
    "        if not os.path.exists(img_root):\n",
    "            os.makedirs(img_root)\n",
    "        if not os.path.exists(label_root):\n",
    "            os.makedirs(label_root)\n",
    "        np.save(os.path.join(img_root, f\"subj_{subj_idx}\"), image)\n",
    "        np.save(os.path.join(label_root, f\"subj_{subj_idx}\"), label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megamedical",
   "language": "python",
   "name": "megamedical"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
